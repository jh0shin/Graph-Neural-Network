       #!/usr/bin/env python3
       ###
       # test code from https://towardsdatascience.com/start-with-graph-convolutional-neural-networks-using-dgl-cf9becc570e1
       ###
       
       # To training neural network with GPU, you have to remove (#) in
       # CPU -> cuda memory copy line of graph and Net
       
>>>>>> import dgl
>>>>>> import dgl.function as fn
>>>>>> import torch as th
>>>>>> import torch.nn as nn
>>>>>> import torch.nn.functional as F
       
>>>>>> from dgl import DGLGraph
>>>>>> from dgl.data import CoraGraphDataset
>>>>>> from dgl.nn import GraphConv
       
>>>>>> import numpy as np
       
>>>>>> import sys
>>>>>> import trace
       
>>>>>> def main():
           ########################################
           # Import Cora dataset
           ########################################
    1:     dataset = CoraGraphDataset()
    1:     g = dataset[0]
    1:     g = g.to('cuda:0')                # graph to cuda memory
    1:     features = g.ndata['feat']
    1:     labels = g.ndata['label']
    1:     train_mask = g.ndata['train_mask']
    1:     test_mask = g.ndata['test_mask']
       
           ########################################
           # GCN network class declaration
           ########################################
    2:     class Net(nn.Module):
    1:         def __init__(self):
    1:             super(Net, self).__init__()
    1:             self.layer1 = GraphConv(1433, 8*16) #activation default=None
    1:             self.layer2 = GraphConv(8*16, 7)    #activation default=None
       
       
    1:         def forward(self, g, features):
  400:             x1 = F.relu(self.layer1(g, features)) #ReLU activation function
  400:             x2 = self.layer2(g, x1)
  400:             return x2
       
    1:     net = Net()
    1:     net = net.cuda()                  # GCN to cuda memory
       
           ########################################
           # Evaluate function declaration
           ########################################
    1:     def evaluate(model, g, features, labels, mask):
  200:         model.eval()
  200:         with th.no_grad():
  200:             logits = model(g, features)
  200:             logits = logits[mask]
  200:             labels = labels[mask]
  200:             _, indices = th.max(logits, dim=1)
  200:             correct = th.sum(indices == labels)
  200:             return correct.item() * 1.0 / len(labels)
       
           ########################################
           # Training
           ########################################
    1:     g.add_edges(g.nodes(), g.nodes())
    1:     optimizer = th.optim.Adam(net.parameters(), lr=1e-2)
    1:     loss_list=[]
    1:     acc_list=[]
    1:     all_logits=[]
  201:     for epoch in range(200):
  200:         net.train()
  200:         logits = net(g, features)
               
               #print(logits)
  200:         logp = F.log_softmax(logits, 1)
  200:         all_logits.append(logp)
  200:         loss = F.nll_loss(logp[train_mask], labels[train_mask])
       
  200:         optimizer.zero_grad()
  200:         loss.backward()
  200:         optimizer.step()
       
  200:         acc = evaluate(net, g, features, labels, test_mask)
  200:         loss_list.append(loss.item())
  200:         acc_list.append(acc)
  200:         print(f"{epoch} epoch - accuracy : {acc}  loss : {loss.item()}")
       
       # create a Trace object, telling it what to ignore, and whether to
       # do tracing or line-counting or both.
>>>>>> tracer = trace.Trace(
>>>>>>     ignoredirs=[sys.prefix, sys.exec_prefix],
>>>>>>     trace=0,
>>>>>>     count=1)
       
       # run the new command using the given tracer
>>>>>> tracer.run('main()')
       
       # make a report, placing output in the current directory
>>>>>> r = tracer.results()
>>>>>> r.write_results(show_missing=True, coverdir="./trace_dgl")
