========================================================================
Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.95985s | 100.0%
- Pytorch Geometric              |      1 |     1.42466s | 100.0%
- Random data processing         |      1 |     0.00462s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 9 and 10.
========================================================================
Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 42, in set_diag
    inv_mask = ~mask
RuntimeError: CUDA error: invalid configuration argument
========================================================================
Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 42, in set_diag
    inv_mask = ~mask
RuntimeError: CUDA error: invalid configuration argument
========================================================================
Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 42, in set_diag
    inv_mask = ~mask
RuntimeError: CUDA error: invalid configuration argument
========================================================================
Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 42, in set_diag
    inv_mask = ~mask
RuntimeError: CUDA error: invalid configuration argument
========================================================================
Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 42, in set_diag
    inv_mask = ~mask
RuntimeError: CUDA error: invalid configuration argument
========================================================================
Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 42, in set_diag
    inv_mask = ~mask
RuntimeError: CUDA error: invalid configuration argument
========================================================================
Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 42, in set_diag
    inv_mask = ~mask
RuntimeError: CUDA error: invalid configuration argument
========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     1.00922s | 100.0%
- Pytorch Geometric              |      1 |     1.42585s | 100.0%
- Random data processing         |      1 |     0.00496s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.83418s | 100.0%
- Pytorch Geometric              |      1 |     1.28215s | 100.0%
- Random data processing         |      1 |     0.00477s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 50 and 48.
========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 40 and 50.
========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 49 and 22.
========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 2 and 15.
========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 42, in set_diag
    inv_mask = ~mask
RuntimeError: CUDA error: invalid configuration argument
========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 42, in set_diag
    inv_mask = ~mask
RuntimeError: CUDA error: invalid configuration argument
========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 42, in set_diag
    inv_mask = ~mask
RuntimeError: CUDA error: invalid configuration argument
========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.91112s | 100.0%
- Pytorch Geometric              |      1 |     1.37438s | 100.0%
- Random data processing         |      1 |     0.00483s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.88708s | 100.0%
- Pytorch Geometric              |      1 |     1.47067s | 100.0%
- Random data processing         |      1 |     0.00592s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.85115s | 100.0%
- Pytorch Geometric              |      1 |     1.37178s | 100.0%
- Random data processing         |      1 |     0.00484s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 100 and 98.
========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 91 and 94.
========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 95 and 97.
========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 41 and 25.
========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 42, in set_diag
    inv_mask = ~mask
RuntimeError: CUDA error: invalid configuration argument
========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 42, in set_diag
    inv_mask = ~mask
RuntimeError: CUDA error: invalid configuration argument
========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.95919s | 100.0%
- Pytorch Geometric              |      1 |     1.67057s | 100.0%
- Random data processing         |      1 |     0.00948s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.85268s | 100.0%
- Pytorch Geometric              |      1 |     1.52091s | 100.0%
- Random data processing         |      1 |     0.00914s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     1.01613s | 100.0%
- Pytorch Geometric              |      1 |     1.56215s | 100.0%
- Random data processing         |      1 |     0.00668s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.84570s | 100.0%
- Pytorch Geometric              |      1 |     1.37331s | 100.0%
- Random data processing         |      1 |     0.00604s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     1.01441s | 100.0%
- Pytorch Geometric              |      1 |     1.71160s | 100.0%
- Random data processing         |      1 |     0.00635s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.89439s | 100.0%
- Pytorch Geometric              |      1 |     2.13917s | 100.0%
- Random data processing         |      1 |     0.00781s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 971 and 998.
========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 965 and 987.
========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 986 and 991.
========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     1.18760s | 100.0%
- Pytorch Geometric              |      1 |     4.93418s | 100.0%
- Random data processing         |      1 |     0.20800s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     1.01731s | 100.0%
- Pytorch Geometric              |      1 |     3.23476s | 100.0%
- Random data processing         |      1 |     0.13355s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.88213s | 100.0%
- Pytorch Geometric              |      1 |     1.82620s | 100.0%
- Random data processing         |      1 |     0.02129s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.96665s | 100.0%
- Pytorch Geometric              |      1 |     1.76186s | 100.0%
- Random data processing         |      1 |     0.01466s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     1.02177s | 100.0%
- Pytorch Geometric              |      1 |     1.61154s | 100.0%
- Random data processing         |      1 |     0.01163s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 4999 and 5000.
========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 4999 and 4998.
========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 170, in <module>
    out = model(data_dgl, node_features)
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/nn/pytorch/utils.py", line 223, in forward
    feats = module(graph, *feats)
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/nn/pytorch/conv/graphconv.py", line 414, in forward
    feat_src = feat_src * norm
RuntimeError: The size of tensor a (5000) must match the size of tensor b (4992) at non-singleton dimension 0
========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 4948 and 4999.
========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     2.86516s | 100.0%
- Pytorch Geometric              |      1 |    17.80119s | 100.0%
- Random data processing         |      1 |     1.15145s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     1.93475s | 100.0%
- Pytorch Geometric              |      1 |     9.22798s | 100.0%
- Random data processing         |      1 |     0.56202s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.96733s | 100.0%
- Pytorch Geometric              |      1 |     2.76539s | 100.0%
- Random data processing         |      1 |     0.09211s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.90512s | 100.0%
- Pytorch Geometric              |      1 |     2.12729s | 100.0%
- Random data processing         |      1 |     0.04160s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     1.01064s | 100.0%
- Pytorch Geometric              |      1 |     1.82246s | 100.0%
- Random data processing         |      1 |     0.01986s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.87384s | 100.0%
- Pytorch Geometric              |      1 |     1.65469s | 100.0%
- Random data processing         |      1 |     0.01746s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 10000 and 9999.
========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 10000 and 9999.
========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 10000 and 9995.
========================================================================
Killed
========================================================================
Killed
========================================================================
Using backend: pytorch
Number of node : 50000, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |    11.87878s | 100.0%
- Pytorch Geometric              |      1 |    52.82870s | 100.0%
- Random data processing         |      1 |     4.09798s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 50000, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     6.59757s | 100.0%
- Pytorch Geometric              |      1 |    27.28897s | 100.0%
- Random data processing         |      1 |     1.83591s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 50000, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     2.35859s | 100.0%
- Pytorch Geometric              |      1 |     6.65721s | 100.0%
- Random data processing         |      1 |     0.31086s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 50000, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     1.88712s | 100.0%
- Pytorch Geometric              |      1 |     4.16180s | 100.0%
- Random data processing         |      1 |     0.16801s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 50000, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     1.38323s | 100.0%
- Pytorch Geometric              |      1 |     2.42787s | 100.0%
- Random data processing         |      1 |     0.07161s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 50000, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 50000 and 49999.
========================================================================
Using backend: pytorch
Number of node : 50000, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 170, in <module>
    out = model(data_dgl, node_features)
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/nn/pytorch/utils.py", line 223, in forward
    feats = module(graph, *feats)
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/nn/pytorch/conv/graphconv.py", line 414, in forward
    feat_src = feat_src * norm
RuntimeError: The size of tensor a (50000) must match the size of tensor b (49999) at non-singleton dimension 0
========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 112, in <module>
    adj = sparse.random(MAT_SIZE, MAT_SIZE, density=DENSITY, dtype=np.float32, random_state=np.random.default_rng())
  File "/home/junho/.local/lib/python3.8/site-packages/scipy/sparse/construct.py", line 806, in random
    ind = random_state.choice(mn, size=k, replace=False)
  File "_generator.pyx", line 788, in numpy.random._generator.Generator.choice
numpy.core._exceptions.MemoryError: Unable to allocate 74.5 GiB for an array with shape (10000000000,) and data type int64
========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 112, in <module>
    adj = sparse.random(MAT_SIZE, MAT_SIZE, density=DENSITY, dtype=np.float32, random_state=np.random.default_rng())
  File "/home/junho/.local/lib/python3.8/site-packages/scipy/sparse/construct.py", line 806, in random
    ind = random_state.choice(mn, size=k, replace=False)
  File "_generator.pyx", line 788, in numpy.random._generator.Generator.choice
numpy.core._exceptions.MemoryError: Unable to allocate 74.5 GiB for an array with shape (10000000000,) and data type int64
========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 52, in set_diag
    new_col[mask] = col
RuntimeError: CUDA out of memory. Tried to allocate 764.00 MiB (GPU 0; 8.00 GiB total capacity; 5.46 GiB already allocated; 0 bytes free; 6.12 GiB reserved in total by PyTorch)
========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 182, in forward
    out = self.propagate(edge_index, x=x, edge_weight=edge_weight,
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 226, in propagate
    out = self.message_and_aggregate(edge_index, **msg_aggr_kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 194, in message_and_aggregate
    return matmul(adj_t, x, reduce=self.aggr)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/matmul.py", line 133, in matmul
    return spmm(src, other, reduce)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/matmul.py", line 69, in spmm
    return spmm_sum(src, other)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/matmul.py", line 23, in spmm_sum
    csr2csc = src.storage.csr2csc()
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/storage.py", line 353, in csr2csc
    csr2csc = idx.argsort()
RuntimeError: CUDA out of memory. Tried to allocate 766.00 MiB (GPU 0; 8.00 GiB total capacity; 5.85 GiB already allocated; 0 bytes free; 6.23 GiB reserved in total by PyTorch)
========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     6.68005s | 100.0%
- Pytorch Geometric              |      1 |    25.64044s | 100.0%
- Random data processing         |      1 |     1.51383s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     4.33751s | 100.0%
- Pytorch Geometric              |      1 |    13.75675s | 100.0%
- Random data processing         |      1 |     0.65117s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     2.40670s | 100.0%
- Pytorch Geometric              |      1 |     4.57580s | 100.0%
- Random data processing         |      1 |     0.18236s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     2.21663s | 100.0%
- Pytorch Geometric              |      1 |     3.68916s | 100.0%
- Random data processing         |      1 |     0.13804s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 100000 and 99999.
========================================================================
Using backend: pytorch
Number of node : 200000, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 112, in <module>
    adj = sparse.random(MAT_SIZE, MAT_SIZE, density=DENSITY, dtype=np.float32, random_state=np.random.default_rng())
  File "/home/junho/.local/lib/python3.8/site-packages/scipy/sparse/construct.py", line 806, in random
    ind = random_state.choice(mn, size=k, replace=False)
  File "_generator.pyx", line 788, in numpy.random._generator.Generator.choice
numpy.core._exceptions.MemoryError: Unable to allocate 298. GiB for an array with shape (40000000000,) and data type int64
========================================================================
Using backend: pytorch
Number of node : 200000, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 112, in <module>
    adj = sparse.random(MAT_SIZE, MAT_SIZE, density=DENSITY, dtype=np.float32, random_state=np.random.default_rng())
  File "/home/junho/.local/lib/python3.8/site-packages/scipy/sparse/construct.py", line 806, in random
    ind = random_state.choice(mn, size=k, replace=False)
  File "_generator.pyx", line 788, in numpy.random._generator.Generator.choice
numpy.core._exceptions.MemoryError: Unable to allocate 298. GiB for an array with shape (40000000000,) and data type int64
========================================================================
Using backend: pytorch
Number of node : 200000, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 123, in <module>
    data_pyg = SparseTensor.from_scipy(adj).to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/tensor.py", line 452, in to
    self = self.device_as(torch.tensor(0., device=device), non_blocking)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/tensor.py", line 142, in device_as
    return self.from_storage(self.storage.device_as(tensor, non_blocking))
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/storage.py", line 495, in device_as
    value = value.to(tensor.device, non_blocking=non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 1.49 GiB (GPU 0; 8.00 GiB total capacity; 6.06 GiB already allocated; 0 bytes free; 6.08 GiB reserved in total by PyTorch)
========================================================================
Using backend: pytorch
Number of node : 200000, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 37, in set_diag
    src = remove_diag(src, k=k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 12, in remove_diag
    new_row, new_col = row[inv_mask], col[inv_mask]
RuntimeError: CUDA out of memory. Tried to allocate 1.49 GiB (GPU 0; 8.00 GiB total capacity; 5.50 GiB already allocated; 416.84 MiB free; 5.52 GiB reserved in total by PyTorch)
========================================================================
Using backend: pytorch
Number of node : 200000, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 170, in <module>
    out = model(data_dgl, node_features)
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/nn/pytorch/utils.py", line 223, in forward
    feats = module(graph, *feats)
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/nn/pytorch/conv/graphconv.py", line 388, in forward
    if (graph.in_degrees() == 0).any():
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/heterograph.py", line 3496, in in_degrees
    deg = self._graph.in_degrees(etid, v_tensor)
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/heterograph_index.py", line 577, in in_degrees
    return F.from_dgl_nd(_CAPI_DGLHeteroInDegrees(
  File "dgl/_ffi/_cython/./function.pxi", line 287, in dgl._ffi._cy3.core.FunctionBase.__call__
  File "dgl/_ffi/_cython/./function.pxi", line 222, in dgl._ffi._cy3.core.FuncCall
  File "dgl/_ffi/_cython/./function.pxi", line 211, in dgl._ffi._cy3.core.FuncCall3
  File "dgl/_ffi/_cython/./base.pxi", line 155, in dgl._ffi._cy3.core.CALL
dgl._ffi.base.DGLError: [18:48:01] /opt/dgl/src/runtime/cuda/cuda_device_api.cc:97: Check failed: e == cudaSuccess || e == cudaErrorCudartUnloading: CUDA: out of memory
Stack trace:
  [bt] (0) /home/junho/.local/lib/python3.8/site-packages/dgl/libdgl.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x4f) [0x7f1ec7902c4f]
  [bt] (1) /home/junho/.local/lib/python3.8/site-packages/dgl/libdgl.so(dgl::runtime::CUDADeviceAPI::AllocDataSpace(DLContext, unsigned long, unsigned long, DLDataType)+0x108) [0x7f1ec8223078]
  [bt] (2) /home/junho/.local/lib/python3.8/site-packages/dgl/libdgl.so(dgl::runtime::WorkspacePool::AllocWorkspace(DLContext, unsigned long)+0x154) [0x7f1ec80c7f24]
  [bt] (3) /home/junho/.local/lib/python3.8/site-packages/dgl/libdgl.so(std::pair<dgl::runtime::NDArray, dgl::runtime::NDArray> dgl::aten::impl::Sort<(DLDeviceType)2, long>(dgl::runtime::NDArray, int)+0x134) [0x7f1ec824ae84]
  [bt] (4) /home/junho/.local/lib/python3.8/site-packages/dgl/libdgl.so(dgl::aten::Sort(dgl::runtime::NDArray, int)+0x1f2) [0x7f1ec78e8d52]
  [bt] (5) /home/junho/.local/lib/python3.8/site-packages/dgl/libdgl.so(void dgl::aten::impl::COOSort_<(DLDeviceType)2, long>(dgl::aten::COOMatrix*, bool)+0x5b) [0x7f1ec82554db]
  [bt] (6) /home/junho/.local/lib/python3.8/site-packages/dgl/libdgl.so(dgl::aten::COOSort_(dgl::aten::COOMatrix*, bool)+0x344) [0x7f1ec78e55c4]
  [bt] (7) /home/junho/.local/lib/python3.8/site-packages/dgl/libdgl.so(dgl::aten::COOSort(dgl::aten::COOMatrix, bool)+0x471) [0x7f1ec792ac61]
  [bt] (8) /home/junho/.local/lib/python3.8/site-packages/dgl/libdgl.so(dgl::aten::CSRMatrix dgl::aten::impl::COOToCSR<(DLDeviceType)2, long>(dgl::aten::COOMatrix)+0xbd) [0x7f1ec825319d]


========================================================================
Using backend: pytorch
Number of node : 200000, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |    13.56222s | 100.0%
- Pytorch Geometric              |      1 |    54.80386s | 100.0%
- Random data processing         |      1 |     2.83597s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 200000, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     5.50491s | 100.0%
- Pytorch Geometric              |      1 |    13.80116s | 100.0%
- Random data processing         |      1 |     0.67038s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 200000, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     4.45228s | 100.0%
- Pytorch Geometric              |      1 |     8.72933s | 100.0%
- Random data processing         |      1 |     0.39023s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 200000, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     3.60535s | 100.0%
- Pytorch Geometric              |      1 |     5.22408s | 100.0%
- Random data processing         |      1 |     0.24020s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 300000, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 112, in <module>
    adj = sparse.random(MAT_SIZE, MAT_SIZE, density=DENSITY, dtype=np.float32, random_state=np.random.default_rng())
  File "/home/junho/.local/lib/python3.8/site-packages/scipy/sparse/construct.py", line 806, in random
    ind = random_state.choice(mn, size=k, replace=False)
  File "_generator.pyx", line 788, in numpy.random._generator.Generator.choice
numpy.core._exceptions.MemoryError: Unable to allocate 671. GiB for an array with shape (90000000000,) and data type int64
========================================================================
Using backend: pytorch
Number of node : 300000, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 112, in <module>
    adj = sparse.random(MAT_SIZE, MAT_SIZE, density=DENSITY, dtype=np.float32, random_state=np.random.default_rng())
  File "/home/junho/.local/lib/python3.8/site-packages/scipy/sparse/construct.py", line 806, in random
    ind = random_state.choice(mn, size=k, replace=False)
  File "_generator.pyx", line 788, in numpy.random._generator.Generator.choice
numpy.core._exceptions.MemoryError: Unable to allocate 671. GiB for an array with shape (90000000000,) and data type int64
========================================================================
Killed
========================================================================
Killed
========================================================================
Using backend: pytorch
Number of node : 300000, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 182, in forward
    out = self.propagate(edge_index, x=x, edge_weight=edge_weight,
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 226, in propagate
    out = self.message_and_aggregate(edge_index, **msg_aggr_kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 194, in message_and_aggregate
    return matmul(adj_t, x, reduce=self.aggr)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/matmul.py", line 133, in matmul
    return spmm(src, other, reduce)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/matmul.py", line 69, in spmm
    return spmm_sum(src, other)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/matmul.py", line 23, in spmm_sum
    csr2csc = src.storage.csr2csc()
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/storage.py", line 353, in csr2csc
    csr2csc = idx.argsort()
RuntimeError: CUDA out of memory. Tried to allocate 1.35 GiB (GPU 0; 8.00 GiB total capacity; 5.67 GiB already allocated; 84.25 MiB free; 5.89 GiB reserved in total by PyTorch)
========================================================================
Using backend: pytorch
Number of node : 300000, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 182, in forward
    out = self.propagate(edge_index, x=x, edge_weight=edge_weight,
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 226, in propagate
    out = self.message_and_aggregate(edge_index, **msg_aggr_kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 194, in message_and_aggregate
    return matmul(adj_t, x, reduce=self.aggr)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/matmul.py", line 133, in matmul
    return spmm(src, other, reduce)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/matmul.py", line 69, in spmm
    return spmm_sum(src, other)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/matmul.py", line 23, in spmm_sum
    csr2csc = src.storage.csr2csc()
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/storage.py", line 353, in csr2csc
    csr2csc = idx.argsort()
RuntimeError: CUDA out of memory. Tried to allocate 692.00 MiB (GPU 0; 8.00 GiB total capacity; 5.81 GiB already allocated; 0 bytes free; 6.23 GiB reserved in total by PyTorch)
========================================================================
Using backend: pytorch
Number of node : 300000, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     9.44792s | 100.0%
- Pytorch Geometric              |      1 |    27.28084s | 100.0%
- Random data processing         |      1 |     1.42556s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 300000, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     6.87873s | 100.0%
- Pytorch Geometric              |      1 |    15.71275s | 100.0%
- Random data processing         |      1 |     0.75845s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 300000, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     5.00991s | 100.0%
- Pytorch Geometric              |      1 |     7.26096s | 100.0%
- Random data processing         |      1 |     0.38458s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     1.04504s | 100.0%
- Pytorch Geometric              |      1 |     1.62137s | 100.0%
- Random data processing         |      1 |     0.00535s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.98762s | 100.0%
- Pytorch Geometric              |      1 |     1.59327s | 100.0%
- Random data processing         |      1 |     0.00540s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.86379s | 100.0%
- Pytorch Geometric              |      1 |     1.42666s | 100.0%
- Random data processing         |      1 |     0.00517s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 100
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.86833s | 100.0%
- Pytorch Geometric              |      1 |     1.46326s | 100.0%
- Random data processing         |      1 |     0.00518s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 499 and 500.
========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 500 and 498.
========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 498 and 463.
========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 444 and 472.
========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 100
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 447 and 297.

========================================================================
========================================================================
========================================================================
========================================================================
========================================================================
========================================================================
========================================================================
========================================================================
========================================================================
========================================================================
========================================================================
================================================================================================================================================
Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 9 and 10.
========================================================================
Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 8 and 9.
========================================================================
Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 1 and 4.
========================================================================
Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 42, in set_diag
    inv_mask = ~mask
RuntimeError: CUDA error: invalid configuration argument
========================================================================
Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 42, in set_diag
    inv_mask = ~mask
RuntimeError: CUDA error: invalid configuration argument
========================================================================
Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 42, in set_diag
    inv_mask = ~mask
RuntimeError: CUDA error: invalid configuration argument
========================================================================
Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 42, in set_diag
    inv_mask = ~mask
RuntimeError: CUDA error: invalid configuration argument
========================================================================
Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 42, in set_diag
    inv_mask = ~mask
RuntimeError: CUDA error: invalid configuration argument
========================================================================
Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 42, in set_diag
    inv_mask = ~mask
RuntimeError: CUDA error: invalid configuration argument
========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.30779s | 100.0%
- Pytorch Geometric              |      1 |     0.17254s | 100.0%
- Random data processing         |      1 |     0.00657s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.32735s | 100.0%
- Pytorch Geometric              |      1 |     0.16085s | 100.0%
- Random data processing         |      1 |     0.00643s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 48 and 50.
========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 50 and 49.
========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 22 and 37.
========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 15 and 23.
========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 42, in set_diag
    inv_mask = ~mask
RuntimeError: CUDA error: invalid configuration argument
========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 42, in set_diag
    inv_mask = ~mask
RuntimeError: CUDA error: invalid configuration argument
========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 42, in set_diag
    inv_mask = ~mask
RuntimeError: CUDA error: invalid configuration argument
========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.28348s | 100.0%
- Pytorch Geometric              |      1 |     0.17513s | 100.0%
- Random data processing         |      1 |     0.00473s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.29990s | 100.0%
- Pytorch Geometric              |      1 |     0.17035s | 100.0%
- Random data processing         |      1 |     0.00553s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 98 and 99.
========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 99 and 100.
========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 75 and 97.
========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 78 and 48.
========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 76 and 79.
========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 42, in set_diag
    inv_mask = ~mask
RuntimeError: CUDA error: invalid configuration argument
========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 42, in set_diag
    inv_mask = ~mask
RuntimeError: CUDA error: invalid configuration argument
========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.30925s | 100.0%
- Pytorch Geometric              |      1 |     0.21621s | 100.0%
- Random data processing         |      1 |     0.00737s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.31808s | 100.0%
- Pytorch Geometric              |      1 |     0.18878s | 100.0%
- Random data processing         |      1 |     0.00548s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.29273s | 100.0%
- Pytorch Geometric              |      1 |     0.20801s | 100.0%
- Random data processing         |      1 |     0.00552s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.28432s | 100.0%
- Pytorch Geometric              |      1 |     0.16754s | 100.0%
- Random data processing         |      1 |     0.00585s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 499 and 498.
========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 499 and 498.
========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 498 and 465.
========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 447 and 494.
========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 275 and 363.
========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.28455s | 100.0%
- Pytorch Geometric              |      1 |     0.22147s | 100.0%
- Random data processing         |      1 |     0.01016s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.28762s | 100.0%
- Pytorch Geometric              |      1 |     0.18588s | 100.0%
- Random data processing         |      1 |     0.00761s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.29730s | 100.0%
- Pytorch Geometric              |      1 |     0.20292s | 100.0%
- Random data processing         |      1 |     0.00844s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.29504s | 100.0%
- Pytorch Geometric              |      1 |     0.20357s | 100.0%
- Random data processing         |      1 |     0.00548s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.33371s | 100.0%
- Pytorch Geometric              |      1 |     0.18430s | 100.0%
- Random data processing         |      1 |     0.00573s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 170, in <module>
    out = model(data_dgl, node_features)
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/nn/pytorch/utils.py", line 223, in forward
    feats = module(graph, *feats)
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/nn/pytorch/conv/graphconv.py", line 414, in forward
    feat_src = feat_src * norm
RuntimeError: The size of tensor a (1000) must match the size of tensor b (999) at non-singleton dimension 0
========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 980 and 1000.
========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 993 and 988.
========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 994 and 934.
========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.31905s | 100.0%
- Pytorch Geometric              |      1 |     0.73452s | 100.0%
- Random data processing         |      1 |     0.24113s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.27707s | 100.0%
- Pytorch Geometric              |      1 |     0.43363s | 100.0%
- Random data processing         |      1 |     0.13467s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.32488s | 100.0%
- Pytorch Geometric              |      1 |     0.22770s | 100.0%
- Random data processing         |      1 |     0.02056s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.27134s | 100.0%
- Pytorch Geometric              |      1 |     0.21490s | 100.0%
- Random data processing         |      1 |     0.01963s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.28117s | 100.0%
- Pytorch Geometric              |      1 |     0.19815s | 100.0%
- Random data processing         |      1 |     0.01441s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 5000 and 4999.
========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.27992s | 100.0%
- Pytorch Geometric              |      1 |     0.17487s | 100.0%
- Random data processing         |      1 |     0.01235s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 5000 and 4999.
========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 4990 and 4986.
========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.65020s | 100.0%
- Pytorch Geometric              |      1 |     2.65477s | 100.0%
- Random data processing         |      1 |     0.86206s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.43308s | 100.0%
- Pytorch Geometric              |      1 |     1.30649s | 100.0%
- Random data processing         |      1 |     0.59990s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.30766s | 100.0%
- Pytorch Geometric              |      1 |     0.37856s | 100.0%
- Random data processing         |      1 |     0.08324s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.31889s | 100.0%
- Pytorch Geometric              |      1 |     0.27985s | 100.0%
- Random data processing         |      1 |     0.05466s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.29010s | 100.0%
- Pytorch Geometric              |      1 |     0.24050s | 100.0%
- Random data processing         |      1 |     0.01945s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.31036s | 100.0%
- Pytorch Geometric              |      1 |     0.21013s | 100.0%
- Random data processing         |      1 |     0.01755s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 9999 and 10000.
========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 9997 and 9999.
========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 9998 and 9984.
========================================================================
Killed
========================================================================
Killed
========================================================================
Using backend: pytorch
Number of node : 50000, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     2.14872s | 100.0%
- Pytorch Geometric              |      1 |     7.65784s | 100.0%
- Random data processing         |      1 |     4.45422s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 50000, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     1.07823s | 100.0%
- Pytorch Geometric              |      1 |     3.76629s | 100.0%
- Random data processing         |      1 |     1.93217s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 50000, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.52771s | 100.0%
- Pytorch Geometric              |      1 |     0.87877s | 100.0%
- Random data processing         |      1 |     0.32868s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 50000, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.39173s | 100.0%
- Pytorch Geometric              |      1 |     0.53649s | 100.0%
- Random data processing         |      1 |     0.16473s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 50000, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.35352s | 100.0%
- Pytorch Geometric              |      1 |     0.30970s | 100.0%
- Random data processing         |      1 |     0.07381s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 50000, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.31518s | 100.0%
- Pytorch Geometric              |      1 |     0.28228s | 100.0%
- Random data processing         |      1 |     0.06450s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 50000, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 50000 and 49998.
========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 112, in <module>
    adj = sparse.random(MAT_SIZE, MAT_SIZE, density=DENSITY, dtype=np.float32, random_state=np.random.default_rng())
  File "/home/junho/.local/lib/python3.8/site-packages/scipy/sparse/construct.py", line 806, in random
    ind = random_state.choice(mn, size=k, replace=False)
  File "_generator.pyx", line 788, in numpy.random._generator.Generator.choice
numpy.core._exceptions.MemoryError: Unable to allocate 74.5 GiB for an array with shape (10000000000,) and data type int64
========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 112, in <module>
    adj = sparse.random(MAT_SIZE, MAT_SIZE, density=DENSITY, dtype=np.float32, random_state=np.random.default_rng())
  File "/home/junho/.local/lib/python3.8/site-packages/scipy/sparse/construct.py", line 806, in random
    ind = random_state.choice(mn, size=k, replace=False)
  File "_generator.pyx", line 788, in numpy.random._generator.Generator.choice
numpy.core._exceptions.MemoryError: Unable to allocate 74.5 GiB for an array with shape (10000000000,) and data type int64
========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 52, in set_diag
    new_col[mask] = col
RuntimeError: CUDA out of memory. Tried to allocate 764.00 MiB (GPU 0; 8.00 GiB total capacity; 5.46 GiB already allocated; 0 bytes free; 6.12 GiB reserved in total by PyTorch)
========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 182, in forward
    out = self.propagate(edge_index, x=x, edge_weight=edge_weight,
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 226, in propagate
    out = self.message_and_aggregate(edge_index, **msg_aggr_kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 194, in message_and_aggregate
    return matmul(adj_t, x, reduce=self.aggr)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/matmul.py", line 133, in matmul
    return spmm(src, other, reduce)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/matmul.py", line 69, in spmm
    return spmm_sum(src, other)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/matmul.py", line 23, in spmm_sum
    csr2csc = src.storage.csr2csc()
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/storage.py", line 353, in csr2csc
    csr2csc = idx.argsort()
RuntimeError: CUDA out of memory. Tried to allocate 766.00 MiB (GPU 0; 8.00 GiB total capacity; 5.85 GiB already allocated; 0 bytes free; 6.23 GiB reserved in total by PyTorch)
========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.97958s | 100.0%
- Pytorch Geometric              |      1 |     3.14568s | 100.0%
- Random data processing         |      1 |     1.35911s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.69819s | 100.0%
- Pytorch Geometric              |      1 |     1.67867s | 100.0%
- Random data processing         |      1 |     0.69305s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.40740s | 100.0%
- Pytorch Geometric              |      1 |     0.51983s | 100.0%
- Random data processing         |      1 |     0.17720s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.40105s | 100.0%
- Pytorch Geometric              |      1 |     0.41584s | 100.0%
- Random data processing         |      1 |     0.13886s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 170, in <module>
    out = model(data_dgl, node_features)
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/nn/pytorch/utils.py", line 223, in forward
    feats = module(graph, *feats)
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/nn/pytorch/conv/graphconv.py", line 414, in forward
    feat_src = feat_src * norm
RuntimeError: The size of tensor a (100000) must match the size of tensor b (99999) at non-singleton dimension 0
========================================================================
Using backend: pytorch
Number of node : 200000, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 112, in <module>
    adj = sparse.random(MAT_SIZE, MAT_SIZE, density=DENSITY, dtype=np.float32, random_state=np.random.default_rng())
  File "/home/junho/.local/lib/python3.8/site-packages/scipy/sparse/construct.py", line 806, in random
    ind = random_state.choice(mn, size=k, replace=False)
  File "_generator.pyx", line 788, in numpy.random._generator.Generator.choice
numpy.core._exceptions.MemoryError: Unable to allocate 298. GiB for an array with shape (40000000000,) and data type int64
========================================================================
Using backend: pytorch
Number of node : 200000, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 112, in <module>
    adj = sparse.random(MAT_SIZE, MAT_SIZE, density=DENSITY, dtype=np.float32, random_state=np.random.default_rng())
  File "/home/junho/.local/lib/python3.8/site-packages/scipy/sparse/construct.py", line 806, in random
    ind = random_state.choice(mn, size=k, replace=False)
  File "_generator.pyx", line 788, in numpy.random._generator.Generator.choice
numpy.core._exceptions.MemoryError: Unable to allocate 298. GiB for an array with shape (40000000000,) and data type int64
========================================================================
Using backend: pytorch
Number of node : 200000, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 123, in <module>
    data_pyg = SparseTensor.from_scipy(adj).to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/tensor.py", line 452, in to
    self = self.device_as(torch.tensor(0., device=device), non_blocking)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/tensor.py", line 142, in device_as
    return self.from_storage(self.storage.device_as(tensor, non_blocking))
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/storage.py", line 495, in device_as
    value = value.to(tensor.device, non_blocking=non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 1.49 GiB (GPU 0; 8.00 GiB total capacity; 6.06 GiB already allocated; 0 bytes free; 6.08 GiB reserved in total by PyTorch)
========================================================================
Using backend: pytorch
Number of node : 200000, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 37, in set_diag
    src = remove_diag(src, k=k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 12, in remove_diag
    new_row, new_col = row[inv_mask], col[inv_mask]
RuntimeError: CUDA out of memory. Tried to allocate 1.49 GiB (GPU 0; 8.00 GiB total capacity; 5.50 GiB already allocated; 419.88 MiB free; 5.52 GiB reserved in total by PyTorch)
========================================================================
Using backend: pytorch
Number of node : 200000, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 170, in <module>
    out = model(data_dgl, node_features)
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/nn/pytorch/utils.py", line 223, in forward
    feats = module(graph, *feats)
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/nn/pytorch/conv/graphconv.py", line 388, in forward
    if (graph.in_degrees() == 0).any():
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/heterograph.py", line 3496, in in_degrees
    deg = self._graph.in_degrees(etid, v_tensor)
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/heterograph_index.py", line 577, in in_degrees
    return F.from_dgl_nd(_CAPI_DGLHeteroInDegrees(
  File "dgl/_ffi/_cython/./function.pxi", line 287, in dgl._ffi._cy3.core.FunctionBase.__call__
  File "dgl/_ffi/_cython/./function.pxi", line 222, in dgl._ffi._cy3.core.FuncCall
  File "dgl/_ffi/_cython/./function.pxi", line 211, in dgl._ffi._cy3.core.FuncCall3
  File "dgl/_ffi/_cython/./base.pxi", line 155, in dgl._ffi._cy3.core.CALL
dgl._ffi.base.DGLError: [20:52:16] /opt/dgl/src/runtime/cuda/cuda_device_api.cc:97: Check failed: e == cudaSuccess || e == cudaErrorCudartUnloading: CUDA: out of memory
Stack trace:
  [bt] (0) /home/junho/.local/lib/python3.8/site-packages/dgl/libdgl.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x4f) [0x7f9007902c4f]
  [bt] (1) /home/junho/.local/lib/python3.8/site-packages/dgl/libdgl.so(dgl::runtime::CUDADeviceAPI::AllocDataSpace(DLContext, unsigned long, unsigned long, DLDataType)+0x108) [0x7f9008223078]
  [bt] (2) /home/junho/.local/lib/python3.8/site-packages/dgl/libdgl.so(dgl::runtime::WorkspacePool::AllocWorkspace(DLContext, unsigned long)+0x154) [0x7f90080c7f24]
  [bt] (3) /home/junho/.local/lib/python3.8/site-packages/dgl/libdgl.so(std::pair<dgl::runtime::NDArray, dgl::runtime::NDArray> dgl::aten::impl::Sort<(DLDeviceType)2, long>(dgl::runtime::NDArray, int)+0x134) [0x7f900824ae84]
  [bt] (4) /home/junho/.local/lib/python3.8/site-packages/dgl/libdgl.so(dgl::aten::Sort(dgl::runtime::NDArray, int)+0x1f2) [0x7f90078e8d52]
  [bt] (5) /home/junho/.local/lib/python3.8/site-packages/dgl/libdgl.so(void dgl::aten::impl::COOSort_<(DLDeviceType)2, long>(dgl::aten::COOMatrix*, bool)+0x5b) [0x7f90082554db]
  [bt] (6) /home/junho/.local/lib/python3.8/site-packages/dgl/libdgl.so(dgl::aten::COOSort_(dgl::aten::COOMatrix*, bool)+0x344) [0x7f90078e55c4]
  [bt] (7) /home/junho/.local/lib/python3.8/site-packages/dgl/libdgl.so(dgl::aten::COOSort(dgl::aten::COOMatrix, bool)+0x471) [0x7f900792ac61]
  [bt] (8) /home/junho/.local/lib/python3.8/site-packages/dgl/libdgl.so(dgl::aten::CSRMatrix dgl::aten::impl::COOToCSR<(DLDeviceType)2, long>(dgl::aten::COOMatrix)+0xbd) [0x7f900825319d]


========================================================================
Using backend: pytorch
Number of node : 200000, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     1.72889s | 100.0%
- Pytorch Geometric              |      1 |     6.57861s | 100.0%
- Random data processing         |      1 |     2.76567s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 200000, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.72568s | 100.0%
- Pytorch Geometric              |      1 |     1.53124s | 100.0%
- Random data processing         |      1 |     0.71038s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 200000, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.60314s | 100.0%
- Pytorch Geometric              |      1 |     0.96068s | 100.0%
- Random data processing         |      1 |     0.38202s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 200000, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.51777s | 100.0%
- Pytorch Geometric              |      1 |     0.55857s | 100.0%
- Random data processing         |      1 |     0.23718s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 300000, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 112, in <module>
    adj = sparse.random(MAT_SIZE, MAT_SIZE, density=DENSITY, dtype=np.float32, random_state=np.random.default_rng())
  File "/home/junho/.local/lib/python3.8/site-packages/scipy/sparse/construct.py", line 806, in random
    ind = random_state.choice(mn, size=k, replace=False)
  File "_generator.pyx", line 788, in numpy.random._generator.Generator.choice
numpy.core._exceptions.MemoryError: Unable to allocate 671. GiB for an array with shape (90000000000,) and data type int64
========================================================================
Using backend: pytorch
Number of node : 300000, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 112, in <module>
    adj = sparse.random(MAT_SIZE, MAT_SIZE, density=DENSITY, dtype=np.float32, random_state=np.random.default_rng())
  File "/home/junho/.local/lib/python3.8/site-packages/scipy/sparse/construct.py", line 806, in random
    ind = random_state.choice(mn, size=k, replace=False)
  File "_generator.pyx", line 788, in numpy.random._generator.Generator.choice
numpy.core._exceptions.MemoryError: Unable to allocate 671. GiB for an array with shape (90000000000,) and data type int64
========================================================================
Killed
========================================================================
Killed
========================================================================
Using backend: pytorch
Number of node : 300000, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 182, in forward
    out = self.propagate(edge_index, x=x, edge_weight=edge_weight,
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 226, in propagate
    out = self.message_and_aggregate(edge_index, **msg_aggr_kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 194, in message_and_aggregate
    return matmul(adj_t, x, reduce=self.aggr)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/matmul.py", line 133, in matmul
    return spmm(src, other, reduce)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/matmul.py", line 69, in spmm
    return spmm_sum(src, other)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/matmul.py", line 23, in spmm_sum
    csr2csc = src.storage.csr2csc()
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/storage.py", line 353, in csr2csc
    csr2csc = idx.argsort()
RuntimeError: CUDA out of memory. Tried to allocate 1.35 GiB (GPU 0; 8.00 GiB total capacity; 5.67 GiB already allocated; 42.32 MiB free; 5.89 GiB reserved in total by PyTorch)
========================================================================
Using backend: pytorch
Number of node : 300000, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 182, in forward
    out = self.propagate(edge_index, x=x, edge_weight=edge_weight,
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 226, in propagate
    out = self.message_and_aggregate(edge_index, **msg_aggr_kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 194, in message_and_aggregate
    return matmul(adj_t, x, reduce=self.aggr)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/matmul.py", line 133, in matmul
    return spmm(src, other, reduce)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/matmul.py", line 69, in spmm
    return spmm_sum(src, other)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/matmul.py", line 23, in spmm_sum
    csr2csc = src.storage.csr2csc()
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/storage.py", line 353, in csr2csc
    csr2csc = idx.argsort()
RuntimeError: CUDA out of memory. Tried to allocate 692.00 MiB (GPU 0; 8.00 GiB total capacity; 5.81 GiB already allocated; 0 bytes free; 6.23 GiB reserved in total by PyTorch)
========================================================================
Using backend: pytorch
Number of node : 300000, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     1.46742s | 100.0%
- Pytorch Geometric              |      1 |     3.43322s | 100.0%
- Random data processing         |      1 |     2.16804s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 300000, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 10
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.91394s | 100.0%
- Pytorch Geometric              |      1 |     1.84229s | 100.0%
- Random data processing         |      1 |     0.78709s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 300000, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 10
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 299999 and 300000.

========================================================================
========================================================================
========================================================================
========================================================================
========================================================================
========================================================================
========================================================================
========================================================================
========================================================================
========================================================================
========================================================================
========================================================================
========================================================================
Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.23280s | 100.0%
- Pytorch Geometric              |      1 |     0.02001s | 100.0%
- Random data processing         |      1 |     0.00511s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 8 and 10.
========================================================================
Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 7 and 6.
========================================================================
Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 42, in set_diag
    inv_mask = ~mask
RuntimeError: CUDA error: invalid configuration argument
========================================================================
Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 42, in set_diag
    inv_mask = ~mask
RuntimeError: CUDA error: invalid configuration argument
========================================================================
Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 42, in set_diag
    inv_mask = ~mask
RuntimeError: CUDA error: invalid configuration argument
========================================================================
Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 42, in set_diag
    inv_mask = ~mask
RuntimeError: CUDA error: invalid configuration argument
========================================================================
Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 42, in set_diag
    inv_mask = ~mask
RuntimeError: CUDA error: invalid configuration argument
========================================================================
Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 42, in set_diag
    inv_mask = ~mask
RuntimeError: CUDA error: invalid configuration argument
========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.21409s | 100.0%
- Pytorch Geometric              |      1 |     0.01865s | 100.0%
- Random data processing         |      1 |     0.00516s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.21086s | 100.0%
- Pytorch Geometric              |      1 |     0.02771s | 100.0%
- Random data processing         |      1 |     0.00444s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 50 and 48.
========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 36 and 48.
========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 18 and 35.
========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 4 and 35.
========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 42, in set_diag
    inv_mask = ~mask
RuntimeError: CUDA error: invalid configuration argument
========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 42, in set_diag
    inv_mask = ~mask
RuntimeError: CUDA error: invalid configuration argument
========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 42, in set_diag
    inv_mask = ~mask
RuntimeError: CUDA error: invalid configuration argument
========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.20411s | 100.0%
- Pytorch Geometric              |      1 |     0.02835s | 100.0%
- Random data processing         |      1 |     0.00548s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.24105s | 100.0%
- Pytorch Geometric              |      1 |     0.02778s | 100.0%
- Random data processing         |      1 |     0.00504s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.20606s | 100.0%
- Pytorch Geometric              |      1 |     0.02631s | 100.0%
- Random data processing         |      1 |     0.00415s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.22490s | 100.0%
- Pytorch Geometric              |      1 |     0.02094s | 100.0%
- Random data processing         |      1 |     0.00509s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 77 and 97.
========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 62 and 55.
========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 89 and 5.
========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 42, in set_diag
    inv_mask = ~mask
RuntimeError: CUDA error: invalid configuration argument
========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 42, in set_diag
    inv_mask = ~mask
RuntimeError: CUDA error: invalid configuration argument
========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.21774s | 100.0%
- Pytorch Geometric              |      1 |     0.02697s | 100.0%
- Random data processing         |      1 |     0.00568s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.21033s | 100.0%
- Pytorch Geometric              |      1 |     0.02660s | 100.0%
- Random data processing         |      1 |     0.00683s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.21878s | 100.0%
- Pytorch Geometric              |      1 |     0.02157s | 100.0%
- Random data processing         |      1 |     0.00518s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.21556s | 100.0%
- Pytorch Geometric              |      1 |     0.02064s | 100.0%
- Random data processing         |      1 |     0.00523s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 500 and 499.
========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 496 and 499.
========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 495 and 462.
========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 491 and 449.
========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 431 and 407.
========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.21597s | 100.0%
- Pytorch Geometric              |      1 |     0.04269s | 100.0%
- Random data processing         |      1 |     0.01323s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.21355s | 100.0%
- Pytorch Geometric              |      1 |     0.03914s | 100.0%
- Random data processing         |      1 |     0.00831s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.21819s | 100.0%
- Pytorch Geometric              |      1 |     0.02844s | 100.0%
- Random data processing         |      1 |     0.00724s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.20669s | 100.0%
- Pytorch Geometric              |      1 |     0.02598s | 100.0%
- Random data processing         |      1 |     0.00640s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.21063s | 100.0%
- Pytorch Geometric              |      1 |     0.02546s | 100.0%
- Random data processing         |      1 |     0.00571s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.21120s | 100.0%
- Pytorch Geometric              |      1 |     0.02580s | 100.0%
- Random data processing         |      1 |     0.00545s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 992 and 997.
========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 982 and 995.
========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 969 and 633.
========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.22403s | 100.0%
- Pytorch Geometric              |      1 |     0.24506s | 100.0%
- Random data processing         |      1 |     0.20871s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.21767s | 100.0%
- Pytorch Geometric              |      1 |     0.13189s | 100.0%
- Random data processing         |      1 |     0.13907s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.20864s | 100.0%
- Pytorch Geometric              |      1 |     0.04395s | 100.0%
- Random data processing         |      1 |     0.01975s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.24290s | 100.0%
- Pytorch Geometric              |      1 |     0.04072s | 100.0%
- Random data processing         |      1 |     0.01451s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.20995s | 100.0%
- Pytorch Geometric              |      1 |     0.02774s | 100.0%
- Random data processing         |      1 |     0.01279s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.21648s | 100.0%
- Pytorch Geometric              |      1 |     0.03278s | 100.0%
- Random data processing         |      1 |     0.01136s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 4996 and 5000.
========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 4997 and 4999.
========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 4986 and 4998.
========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.36180s | 100.0%
- Pytorch Geometric              |      1 |     0.99201s | 100.0%
- Random data processing         |      1 |     0.85469s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.27502s | 100.0%
- Pytorch Geometric              |      1 |     0.53560s | 100.0%
- Random data processing         |      1 |     0.70215s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.22207s | 100.0%
- Pytorch Geometric              |      1 |     0.10462s | 100.0%
- Random data processing         |      1 |     0.08467s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.21053s | 100.0%
- Pytorch Geometric              |      1 |     0.06073s | 100.0%
- Random data processing         |      1 |     0.03749s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.22023s | 100.0%
- Pytorch Geometric              |      1 |     0.04212s | 100.0%
- Random data processing         |      1 |     0.02169s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.23090s | 100.0%
- Pytorch Geometric              |      1 |     0.05024s | 100.0%
- Random data processing         |      1 |     0.01670s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 170, in <module>
    out = model(data_dgl, node_features)
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/nn/pytorch/utils.py", line 223, in forward
    feats = module(graph, *feats)
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/nn/pytorch/conv/graphconv.py", line 414, in forward
    feat_src = feat_src * norm
RuntimeError: The size of tensor a (10000) must match the size of tensor b (9999) at non-singleton dimension 0
========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 10000 and 9999.
========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 9998 and 9993.
========================================================================
Killed
========================================================================
Killed
========================================================================
Using backend: pytorch
Number of node : 50000, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.86792s | 100.0%
- Pytorch Geometric              |      1 |     2.47990s | 100.0%
- Random data processing         |      1 |     4.03381s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 50000, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.43075s | 100.0%
- Pytorch Geometric              |      1 |     1.21842s | 100.0%
- Random data processing         |      1 |     2.09057s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 50000, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.27360s | 100.0%
- Pytorch Geometric              |      1 |     0.23697s | 100.0%
- Random data processing         |      1 |     0.31712s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 50000, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.24820s | 100.0%
- Pytorch Geometric              |      1 |     0.12989s | 100.0%
- Random data processing         |      1 |     0.17954s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 50000, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.20933s | 100.0%
- Pytorch Geometric              |      1 |     0.05893s | 100.0%
- Random data processing         |      1 |     0.07052s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 50000, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.22542s | 100.0%
- Pytorch Geometric              |      1 |     0.05498s | 100.0%
- Random data processing         |      1 |     0.06611s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 50000, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 50000 and 49999.
========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 112, in <module>
    adj = sparse.random(MAT_SIZE, MAT_SIZE, density=DENSITY, dtype=np.float32, random_state=np.random.default_rng())
  File "/home/junho/.local/lib/python3.8/site-packages/scipy/sparse/construct.py", line 806, in random
    ind = random_state.choice(mn, size=k, replace=False)
  File "_generator.pyx", line 788, in numpy.random._generator.Generator.choice
numpy.core._exceptions.MemoryError: Unable to allocate 74.5 GiB for an array with shape (10000000000,) and data type int64
========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 112, in <module>
    adj = sparse.random(MAT_SIZE, MAT_SIZE, density=DENSITY, dtype=np.float32, random_state=np.random.default_rng())
  File "/home/junho/.local/lib/python3.8/site-packages/scipy/sparse/construct.py", line 806, in random
    ind = random_state.choice(mn, size=k, replace=False)
  File "_generator.pyx", line 788, in numpy.random._generator.Generator.choice
numpy.core._exceptions.MemoryError: Unable to allocate 74.5 GiB for an array with shape (10000000000,) and data type int64
========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 52, in set_diag
    new_col[mask] = col
RuntimeError: CUDA out of memory. Tried to allocate 764.00 MiB (GPU 0; 8.00 GiB total capacity; 5.46 GiB already allocated; 0 bytes free; 6.12 GiB reserved in total by PyTorch)
========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 182, in forward
    out = self.propagate(edge_index, x=x, edge_weight=edge_weight,
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 226, in propagate
    out = self.message_and_aggregate(edge_index, **msg_aggr_kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 194, in message_and_aggregate
    return matmul(adj_t, x, reduce=self.aggr)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/matmul.py", line 133, in matmul
    return spmm(src, other, reduce)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/matmul.py", line 69, in spmm
    return spmm_sum(src, other)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/matmul.py", line 23, in spmm_sum
    csr2csc = src.storage.csr2csc()
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/storage.py", line 353, in csr2csc
    csr2csc = idx.argsort()
RuntimeError: CUDA out of memory. Tried to allocate 766.00 MiB (GPU 0; 8.00 GiB total capacity; 5.85 GiB already allocated; 0 bytes free; 6.23 GiB reserved in total by PyTorch)
========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.39796s | 100.0%
- Pytorch Geometric              |      1 |     1.00459s | 100.0%
- Random data processing         |      1 |     1.48634s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.30131s | 100.0%
- Pytorch Geometric              |      1 |     0.47755s | 100.0%
- Random data processing         |      1 |     0.66650s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.23464s | 100.0%
- Pytorch Geometric              |      1 |     0.12088s | 100.0%
- Random data processing         |      1 |     0.18549s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.23341s | 100.0%
- Pytorch Geometric              |      1 |     0.09054s | 100.0%
- Random data processing         |      1 |     0.13601s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.24056s | 100.0%
- Pytorch Geometric              |      1 |     0.07209s | 100.0%
- Random data processing         |      1 |     0.12844s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 200000, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 112, in <module>
    adj = sparse.random(MAT_SIZE, MAT_SIZE, density=DENSITY, dtype=np.float32, random_state=np.random.default_rng())
  File "/home/junho/.local/lib/python3.8/site-packages/scipy/sparse/construct.py", line 806, in random
    ind = random_state.choice(mn, size=k, replace=False)
  File "_generator.pyx", line 788, in numpy.random._generator.Generator.choice
numpy.core._exceptions.MemoryError: Unable to allocate 298. GiB for an array with shape (40000000000,) and data type int64
========================================================================
Using backend: pytorch
Number of node : 200000, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 112, in <module>
    adj = sparse.random(MAT_SIZE, MAT_SIZE, density=DENSITY, dtype=np.float32, random_state=np.random.default_rng())
  File "/home/junho/.local/lib/python3.8/site-packages/scipy/sparse/construct.py", line 806, in random
    ind = random_state.choice(mn, size=k, replace=False)
  File "_generator.pyx", line 788, in numpy.random._generator.Generator.choice
numpy.core._exceptions.MemoryError: Unable to allocate 298. GiB for an array with shape (40000000000,) and data type int64
========================================================================
Using backend: pytorch
Number of node : 200000, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 123, in <module>
    data_pyg = SparseTensor.from_scipy(adj).to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/tensor.py", line 452, in to
    self = self.device_as(torch.tensor(0., device=device), non_blocking)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/tensor.py", line 142, in device_as
    return self.from_storage(self.storage.device_as(tensor, non_blocking))
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/storage.py", line 495, in device_as
    value = value.to(tensor.device, non_blocking=non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 1.49 GiB (GPU 0; 8.00 GiB total capacity; 6.06 GiB already allocated; 0 bytes free; 6.08 GiB reserved in total by PyTorch)
========================================================================
Using backend: pytorch
Number of node : 200000, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 171, in forward
    edge_index = gcn_norm(  # yapf: disable
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 40, in gcn_norm
    adj_t = fill_diag(adj_t, fill_value)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 91, in fill_diag
    return set_diag(src, value.new_full(sizes, fill_value), k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 37, in set_diag
    src = remove_diag(src, k=k)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/diag.py", line 12, in remove_diag
    new_row, new_col = row[inv_mask], col[inv_mask]
RuntimeError: CUDA out of memory. Tried to allocate 1.49 GiB (GPU 0; 8.00 GiB total capacity; 5.50 GiB already allocated; 256.41 MiB free; 5.52 GiB reserved in total by PyTorch)
========================================================================
Using backend: pytorch
Number of node : 200000, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 170, in <module>
    out = model(data_dgl, node_features)
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/nn/pytorch/utils.py", line 223, in forward
    feats = module(graph, *feats)
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/nn/pytorch/conv/graphconv.py", line 388, in forward
    if (graph.in_degrees() == 0).any():
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/heterograph.py", line 3496, in in_degrees
    deg = self._graph.in_degrees(etid, v_tensor)
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/heterograph_index.py", line 577, in in_degrees
    return F.from_dgl_nd(_CAPI_DGLHeteroInDegrees(
  File "dgl/_ffi/_cython/./function.pxi", line 287, in dgl._ffi._cy3.core.FunctionBase.__call__
  File "dgl/_ffi/_cython/./function.pxi", line 222, in dgl._ffi._cy3.core.FuncCall
  File "dgl/_ffi/_cython/./function.pxi", line 211, in dgl._ffi._cy3.core.FuncCall3
  File "dgl/_ffi/_cython/./base.pxi", line 155, in dgl._ffi._cy3.core.CALL
dgl._ffi.base.DGLError: [22:30:45] /opt/dgl/src/runtime/cuda/cuda_device_api.cc:97: Check failed: e == cudaSuccess || e == cudaErrorCudartUnloading: CUDA: out of memory
Stack trace:
  [bt] (0) /home/junho/.local/lib/python3.8/site-packages/dgl/libdgl.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x4f) [0x7f1247902c4f]
  [bt] (1) /home/junho/.local/lib/python3.8/site-packages/dgl/libdgl.so(dgl::runtime::CUDADeviceAPI::AllocDataSpace(DLContext, unsigned long, unsigned long, DLDataType)+0x108) [0x7f1248223078]
  [bt] (2) /home/junho/.local/lib/python3.8/site-packages/dgl/libdgl.so(dgl::runtime::WorkspacePool::AllocWorkspace(DLContext, unsigned long)+0x154) [0x7f12480c7f24]
  [bt] (3) /home/junho/.local/lib/python3.8/site-packages/dgl/libdgl.so(std::pair<dgl::runtime::NDArray, dgl::runtime::NDArray> dgl::aten::impl::Sort<(DLDeviceType)2, long>(dgl::runtime::NDArray, int)+0x134) [0x7f124824ae84]
  [bt] (4) /home/junho/.local/lib/python3.8/site-packages/dgl/libdgl.so(dgl::aten::Sort(dgl::runtime::NDArray, int)+0x1f2) [0x7f12478e8d52]
  [bt] (5) /home/junho/.local/lib/python3.8/site-packages/dgl/libdgl.so(void dgl::aten::impl::COOSort_<(DLDeviceType)2, long>(dgl::aten::COOMatrix*, bool)+0x5b) [0x7f12482554db]
  [bt] (6) /home/junho/.local/lib/python3.8/site-packages/dgl/libdgl.so(dgl::aten::COOSort_(dgl::aten::COOMatrix*, bool)+0x344) [0x7f12478e55c4]
  [bt] (7) /home/junho/.local/lib/python3.8/site-packages/dgl/libdgl.so(dgl::aten::COOSort(dgl::aten::COOMatrix, bool)+0x471) [0x7f124792ac61]
  [bt] (8) /home/junho/.local/lib/python3.8/site-packages/dgl/libdgl.so(dgl::aten::CSRMatrix dgl::aten::impl::COOToCSR<(DLDeviceType)2, long>(dgl::aten::COOMatrix)+0xbd) [0x7f124825319d]


========================================================================
Using backend: pytorch
Number of node : 200000, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.59166s | 100.0%
- Pytorch Geometric              |      1 |     2.02825s | 100.0%
- Random data processing         |      1 |     2.97333s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 200000, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.29753s | 100.0%
- Pytorch Geometric              |      1 |     0.42126s | 100.0%
- Random data processing         |      1 |     0.64370s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 200000, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.24813s | 100.0%
- Pytorch Geometric              |      1 |     0.23424s | 100.0%
- Random data processing         |      1 |     0.43073s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 200000, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.22466s | 100.0%
- Pytorch Geometric              |      1 |     0.11933s | 100.0%
- Random data processing         |      1 |     0.23563s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 300000, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 112, in <module>
    adj = sparse.random(MAT_SIZE, MAT_SIZE, density=DENSITY, dtype=np.float32, random_state=np.random.default_rng())
  File "/home/junho/.local/lib/python3.8/site-packages/scipy/sparse/construct.py", line 806, in random
    ind = random_state.choice(mn, size=k, replace=False)
  File "_generator.pyx", line 788, in numpy.random._generator.Generator.choice
numpy.core._exceptions.MemoryError: Unable to allocate 671. GiB for an array with shape (90000000000,) and data type int64
========================================================================
Using backend: pytorch
Number of node : 300000, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 112, in <module>
    adj = sparse.random(MAT_SIZE, MAT_SIZE, density=DENSITY, dtype=np.float32, random_state=np.random.default_rng())
  File "/home/junho/.local/lib/python3.8/site-packages/scipy/sparse/construct.py", line 806, in random
    ind = random_state.choice(mn, size=k, replace=False)
  File "_generator.pyx", line 788, in numpy.random._generator.Generator.choice
numpy.core._exceptions.MemoryError: Unable to allocate 671. GiB for an array with shape (90000000000,) and data type int64
========================================================================
Killed
========================================================================
Killed
========================================================================
Using backend: pytorch
Number of node : 300000, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 182, in forward
    out = self.propagate(edge_index, x=x, edge_weight=edge_weight,
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 226, in propagate
    out = self.message_and_aggregate(edge_index, **msg_aggr_kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 194, in message_and_aggregate
    return matmul(adj_t, x, reduce=self.aggr)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/matmul.py", line 133, in matmul
    return spmm(src, other, reduce)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/matmul.py", line 69, in spmm
    return spmm_sum(src, other)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/matmul.py", line 23, in spmm_sum
    csr2csc = src.storage.csr2csc()
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/storage.py", line 353, in csr2csc
    csr2csc = idx.argsort()
RuntimeError: CUDA out of memory. Tried to allocate 1.35 GiB (GPU 0; 8.00 GiB total capacity; 5.67 GiB already allocated; 0 bytes free; 5.89 GiB reserved in total by PyTorch)
========================================================================
Using backend: pytorch
Number of node : 300000, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 138, in <module>
    out = model(node_features, data_pyg)[train_idx]
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/sequential.py", line 106, in forward
    out = fn(*[state[key] for key in in_desc])
  File "/home/junho/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 182, in forward
    out = self.propagate(edge_index, x=x, edge_weight=edge_weight,
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 226, in propagate
    out = self.message_and_aggregate(edge_index, **msg_aggr_kwargs)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py", line 194, in message_and_aggregate
    return matmul(adj_t, x, reduce=self.aggr)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/matmul.py", line 133, in matmul
    return spmm(src, other, reduce)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/matmul.py", line 69, in spmm
    return spmm_sum(src, other)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/matmul.py", line 23, in spmm_sum
    csr2csc = src.storage.csr2csc()
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/storage.py", line 353, in csr2csc
    csr2csc = idx.argsort()
RuntimeError: CUDA out of memory. Tried to allocate 692.00 MiB (GPU 0; 8.00 GiB total capacity; 5.81 GiB already allocated; 0 bytes free; 6.23 GiB reserved in total by PyTorch)
========================================================================
Using backend: pytorch
Number of node : 300000, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.61504s | 100.0%
- Pytorch Geometric              |      1 |     0.95185s | 100.0%
- Random data processing         |      1 |     1.36430s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 300000, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 1
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.31671s | 100.0%
- Pytorch Geometric              |      1 |     0.48973s | 100.0%
- Random data processing         |      1 |     0.83453s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 300000, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 1
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 300000 and 299999.
========================================================================
========================================================================
========================================================================
========================================================================
========================================================================
========================================================================
========================================================================
========================================================================
========================================================================
========================================================================
========================================================================
========================================================================


Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.19868s | 100.0%
- Pytorch Geometric              |      1 |     0.00434s | 100.0%
- Random data processing         |      1 |     0.00495s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.19146s | 100.0%
- Pytorch Geometric              |      1 |     0.00329s | 100.0%
- Random data processing         |      1 |     0.00473s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 6 and 3.
========================================================================
Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/scipy/sparse/coo.py", line 147, in __init__
    raise ValueError('cannot infer dimensions from zero '
ValueError: cannot infer dimensions from zero sized index arrays
========================================================================
Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/scipy/sparse/coo.py", line 147, in __init__
    raise ValueError('cannot infer dimensions from zero '
ValueError: cannot infer dimensions from zero sized index arrays
========================================================================
Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/scipy/sparse/coo.py", line 147, in __init__
    raise ValueError('cannot infer dimensions from zero '
ValueError: cannot infer dimensions from zero sized index arrays
========================================================================
Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/scipy/sparse/coo.py", line 147, in __init__
    raise ValueError('cannot infer dimensions from zero '
ValueError: cannot infer dimensions from zero sized index arrays
========================================================================
Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/scipy/sparse/coo.py", line 147, in __init__
    raise ValueError('cannot infer dimensions from zero '
ValueError: cannot infer dimensions from zero sized index arrays
========================================================================
Using backend: pytorch
Number of node : 10, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/scipy/sparse/coo.py", line 147, in __init__
    raise ValueError('cannot infer dimensions from zero '
ValueError: cannot infer dimensions from zero sized index arrays
========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.19632s | 100.0%
- Pytorch Geometric              |      1 |     0.00260s | 100.0%
- Random data processing         |      1 |     0.00445s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.19306s | 100.0%
- Pytorch Geometric              |      1 |     0.00425s | 100.0%
- Random data processing         |      1 |     0.00490s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 45 and 50.
========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 49 and 44.
========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 25 and 12.
========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 33 and 39.
========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/scipy/sparse/coo.py", line 147, in __init__
    raise ValueError('cannot infer dimensions from zero '
ValueError: cannot infer dimensions from zero sized index arrays
========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/scipy/sparse/coo.py", line 147, in __init__
    raise ValueError('cannot infer dimensions from zero '
ValueError: cannot infer dimensions from zero sized index arrays
========================================================================
Using backend: pytorch
Number of node : 50, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/scipy/sparse/coo.py", line 147, in __init__
    raise ValueError('cannot infer dimensions from zero '
ValueError: cannot infer dimensions from zero sized index arrays
========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.21573s | 100.0%
- Pytorch Geometric              |      1 |     0.00418s | 100.0%
- Random data processing         |      1 |     0.00460s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.19230s | 100.0%
- Pytorch Geometric              |      1 |     0.00270s | 100.0%
- Random data processing         |      1 |     0.00517s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 96 and 100.
========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.21723s | 100.0%
- Pytorch Geometric              |      1 |     0.00296s | 100.0%
- Random data processing         |      1 |     0.00554s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 90 and 93.
========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 58 and 66.
========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 100 and 25.
========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/scipy/sparse/coo.py", line 147, in __init__
    raise ValueError('cannot infer dimensions from zero '
ValueError: cannot infer dimensions from zero sized index arrays
========================================================================
Using backend: pytorch
Number of node : 100, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/scipy/sparse/coo.py", line 147, in __init__
    raise ValueError('cannot infer dimensions from zero '
ValueError: cannot infer dimensions from zero sized index arrays
========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.20664s | 100.0%
- Pytorch Geometric              |      1 |     0.00642s | 100.0%
- Random data processing         |      1 |     0.00607s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.20022s | 100.0%
- Pytorch Geometric              |      1 |     0.00299s | 100.0%
- Random data processing         |      1 |     0.00629s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.21282s | 100.0%
- Pytorch Geometric              |      1 |     0.00280s | 100.0%
- Random data processing         |      1 |     0.00594s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.22398s | 100.0%
- Pytorch Geometric              |      1 |     0.00417s | 100.0%
- Random data processing         |      1 |     0.00597s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 497 and 500.
========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.21959s | 100.0%
- Pytorch Geometric              |      1 |     0.00469s | 100.0%
- Random data processing         |      1 |     0.00588s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.21768s | 100.0%
- Pytorch Geometric              |      1 |     0.00300s | 100.0%
- Random data processing         |      1 |     0.00560s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 462 and 474.
========================================================================
Using backend: pytorch
Number of node : 500, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 301 and 359.
========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.20913s | 100.0%
- Pytorch Geometric              |      1 |     0.00977s | 100.0%
- Random data processing         |      1 |     0.01190s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.22739s | 100.0%
- Pytorch Geometric              |      1 |     0.00739s | 100.0%
- Random data processing         |      1 |     0.00892s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.19923s | 100.0%
- Pytorch Geometric              |      1 |     0.00507s | 100.0%
- Random data processing         |      1 |     0.00599s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.20304s | 100.0%
- Pytorch Geometric              |      1 |     0.00303s | 100.0%
- Random data processing         |      1 |     0.00602s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.20048s | 100.0%
- Pytorch Geometric              |      1 |     0.00260s | 100.0%
- Random data processing         |      1 |     0.00563s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.20892s | 100.0%
- Pytorch Geometric              |      1 |     0.00255s | 100.0%
- Random data processing         |      1 |     0.00614s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 991 and 994.
========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 984 and 974.
========================================================================
Using backend: pytorch
Number of node : 1000, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 979 and 988.
========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.20825s | 100.0%
- Pytorch Geometric              |      1 |     0.14723s | 100.0%
- Random data processing         |      1 |     0.21152s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.19960s | 100.0%
- Pytorch Geometric              |      1 |     0.06817s | 100.0%
- Random data processing         |      1 |     0.13344s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.23237s | 100.0%
- Pytorch Geometric              |      1 |     0.01710s | 100.0%
- Random data processing         |      1 |     0.02233s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.20609s | 100.0%
- Pytorch Geometric              |      1 |     0.00972s | 100.0%
- Random data processing         |      1 |     0.01409s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.27314s | 100.0%
- Pytorch Geometric              |      1 |     0.00551s | 100.0%
- Random data processing         |      1 |     0.01226s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 4999 and 5000.
========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 4999 and 4995.
========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 4997 and 4999.
========================================================================
Using backend: pytorch
Number of node : 5000, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 4988 and 4952.
========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.31136s | 100.0%
- Pytorch Geometric              |      1 |     0.76390s | 100.0%
- Random data processing         |      1 |     0.86804s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.28775s | 100.0%
- Pytorch Geometric              |      1 |     0.31931s | 100.0%
- Random data processing         |      1 |     0.61273s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.21495s | 100.0%
- Pytorch Geometric              |      1 |     0.05555s | 100.0%
- Random data processing         |      1 |     0.08839s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.21873s | 100.0%
- Pytorch Geometric              |      1 |     0.02617s | 100.0%
- Random data processing         |      1 |     0.04473s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.23198s | 100.0%
- Pytorch Geometric              |      1 |     0.01038s | 100.0%
- Random data processing         |      1 |     0.02292s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.22611s | 100.0%
- Pytorch Geometric              |      1 |     0.00570s | 100.0%
- Random data processing         |      1 |     0.01861s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.21016s | 100.0%
- Pytorch Geometric              |      1 |     0.00410s | 100.0%
- Random data processing         |      1 |     0.01626s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.20461s | 100.0%
- Pytorch Geometric              |      1 |     0.00318s | 100.0%
- Random data processing         |      1 |     0.01570s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 10000, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 9994 and 9974.
========================================================================
Killed
========================================================================
Killed
========================================================================
Using backend: pytorch
Number of node : 50000, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.71700s | 100.0%
- Pytorch Geometric              |      1 |     1.72070s | 100.0%
- Random data processing         |      1 |     4.15949s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 50000, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.32540s | 100.0%
- Pytorch Geometric              |      1 |     0.81565s | 100.0%
- Random data processing         |      1 |     2.04447s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 50000, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.22938s | 100.0%
- Pytorch Geometric              |      1 |     0.13416s | 100.0%
- Random data processing         |      1 |     0.34556s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 50000, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.20845s | 100.0%
- Pytorch Geometric              |      1 |     0.06487s | 100.0%
- Random data processing         |      1 |     0.17549s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 50000, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.20192s | 100.0%
- Pytorch Geometric              |      1 |     0.01811s | 100.0%
- Random data processing         |      1 |     0.06949s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 50000, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.20462s | 100.0%
- Pytorch Geometric              |      1 |     0.00959s | 100.0%
- Random data processing         |      1 |     0.06605s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 50000, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 49995 and 50000.
========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 112, in <module>
    adj = sparse.random(MAT_SIZE, MAT_SIZE, density=DENSITY, dtype=np.float32, random_state=np.random.default_rng())
  File "/home/junho/.local/lib/python3.8/site-packages/scipy/sparse/construct.py", line 806, in random
    ind = random_state.choice(mn, size=k, replace=False)
  File "_generator.pyx", line 788, in numpy.random._generator.Generator.choice
numpy.core._exceptions.MemoryError: Unable to allocate 74.5 GiB for an array with shape (10000000000,) and data type int64
========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 112, in <module>
    adj = sparse.random(MAT_SIZE, MAT_SIZE, density=DENSITY, dtype=np.float32, random_state=np.random.default_rng())
  File "/home/junho/.local/lib/python3.8/site-packages/scipy/sparse/construct.py", line 806, in random
    ind = random_state.choice(mn, size=k, replace=False)
  File "_generator.pyx", line 788, in numpy.random._generator.Generator.choice
numpy.core._exceptions.MemoryError: Unable to allocate 74.5 GiB for an array with shape (10000000000,) and data type int64
========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     1.34445s | 100.0%
- Pytorch Geometric              |      1 |     7.97272s | 100.0%
- Random data processing         |      1 |    15.28665s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 0.005, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.71549s | 100.0%
- Pytorch Geometric              |      1 |     3.68134s | 100.0%
- Random data processing         |      1 |     8.13029s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.30521s | 100.0%
- Pytorch Geometric              |      1 |     0.62363s | 100.0%
- Random data processing         |      1 |     1.36329s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.25178s | 100.0%
- Pytorch Geometric              |      1 |     0.27194s | 100.0%
- Random data processing         |      1 |     0.63098s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.21610s | 100.0%
- Pytorch Geometric              |      1 |     0.05052s | 100.0%
- Random data processing         |      1 |     0.17866s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.21369s | 100.0%
- Pytorch Geometric              |      1 |     0.02760s | 100.0%
- Random data processing         |      1 |     0.13803s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 100000, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.19455s | 100.0%
- Pytorch Geometric              |      1 |     0.00954s | 100.0%
- Random data processing         |      1 |     0.11610s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 200000, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 112, in <module>
    adj = sparse.random(MAT_SIZE, MAT_SIZE, density=DENSITY, dtype=np.float32, random_state=np.random.default_rng())
  File "/home/junho/.local/lib/python3.8/site-packages/scipy/sparse/construct.py", line 806, in random
    ind = random_state.choice(mn, size=k, replace=False)
  File "_generator.pyx", line 788, in numpy.random._generator.Generator.choice
numpy.core._exceptions.MemoryError: Unable to allocate 298. GiB for an array with shape (40000000000,) and data type int64
========================================================================
Using backend: pytorch
Number of node : 200000, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 112, in <module>
    adj = sparse.random(MAT_SIZE, MAT_SIZE, density=DENSITY, dtype=np.float32, random_state=np.random.default_rng())
  File "/home/junho/.local/lib/python3.8/site-packages/scipy/sparse/construct.py", line 806, in random
    ind = random_state.choice(mn, size=k, replace=False)
  File "_generator.pyx", line 788, in numpy.random._generator.Generator.choice
numpy.core._exceptions.MemoryError: Unable to allocate 298. GiB for an array with shape (40000000000,) and data type int64
========================================================================
Using backend: pytorch
Number of node : 200000, Number of node features : 128, Number of classes : 10
Density : 0.01, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 123, in <module>
    data_pyg = SparseTensor.from_scipy(adj).to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/tensor.py", line 452, in to
    self = self.device_as(torch.tensor(0., device=device), non_blocking)
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/tensor.py", line 142, in device_as
    return self.from_storage(self.storage.device_as(tensor, non_blocking))
  File "/home/junho/.local/lib/python3.8/site-packages/torch_sparse/storage.py", line 495, in device_as
    value = value.to(tensor.device, non_blocking=non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 1.49 GiB (GPU 0; 8.00 GiB total capacity; 6.06 GiB already allocated; 0 bytes free; 6.08 GiB reserved in total by PyTorch)
========================================================================
terminate called after throwing an instance of 'c10::CUDAOutOfMemoryError'
  what():  CUDA out of memory. Tried to allocate 1.49 GiB (GPU 0; 8.00 GiB total capacity; 5.32 GiB already allocated; 552.14 MiB free; 5.33 GiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:288 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f84af22f2f2 in /home/junho/.local/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1bc01 (0x7f84af48dc01 in /home/junho/.local/lib/python3.8/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1c924 (0x7f84af48e924 in /home/junho/.local/lib/python3.8/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1cf43 (0x7f84af48ef43 in /home/junho/.local/lib/python3.8/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::optional<c10::ScalarType>, c10::optional<c10::Layout>, c10::optional<c10::Device>, c10::optional<bool>, c10::optional<c10::MemoryFormat>) + 0x200 (0x7f84b2872110 in /home/junho/.local/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xec0596 (0x7f84b0562596 in /home/junho/.local/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xec063d (0x7f84b056263d in /home/junho/.local/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x165ab19 (0x7f84ec7f6b19 in /home/junho/.local/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x1611277 (0x7f84ec7ad277 in /home/junho/.local/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions, c10::optional<c10::MemoryFormat>) + 0x149 (0x7f84ec651549 in /home/junho/.local/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)
frame #10: torch::empty(c10::ArrayRef<long>, c10::TensorOptions, c10::optional<c10::MemoryFormat>) + 0x9a (0x7f8480bb93bd in /home/junho/.local/lib/python3.8/site-packages/dgl/tensoradapter/pytorch/libtensoradapter_pytorch_1.8.0.so)
frame #11: TAempty + 0x119 (0x7f8480bb586e in /home/junho/.local/lib/python3.8/site-packages/dgl/tensoradapter/pytorch/libtensoradapter_pytorch_1.8.0.so)
frame #12: dgl::runtime::NDArray::Empty(std::vector<long, std::allocator<long> >, DLDataType, DLContext) + 0xb6 (0x7f84580b57b6 in /home/junho/.local/lib/python3.8/site-packages/dgl/libdgl.so)
frame #13: dgl::runtime::NDArray::CopyTo(DLContext const&) const + 0xc0 (0x7f84580eebd0 in /home/junho/.local/lib/python3.8/site-packages/dgl/libdgl.so)
frame #14: dgl::aten::COOMatrix::CopyTo(DLContext const&) const + 0x8c (0x7f845820561c in /home/junho/.local/lib/python3.8/site-packages/dgl/libdgl.so)
frame #15: dgl::UnitGraph::CopyTo(std::shared_ptr<dgl::BaseHeteroGraph>, DLContext const&) + 0x292 (0x7f84581f5d82 in /home/junho/.local/lib/python3.8/site-packages/dgl/libdgl.so)
frame #16: dgl::HeteroGraph::CopyTo(std::shared_ptr<dgl::BaseHeteroGraph>, DLContext const&) + 0xf5 (0x7f84580ffe05 in /home/junho/.local/lib/python3.8/site-packages/dgl/libdgl.so)
frame #17: <unknown function> + 0xdb9beb (0x7f845810cbeb in /home/junho/.local/lib/python3.8/site-packages/dgl/libdgl.so)
frame #18: DGLFuncCall + 0x48 (0x7f8458099918 in /home/junho/.local/lib/python3.8/site-packages/dgl/libdgl.so)
frame #19: <unknown function> + 0x15fa9 (0x7f8480993fa9 in /home/junho/.local/lib/python3.8/site-packages/dgl/_ffi/_cy3/core.cpython-38-x86_64-linux-gnu.so)
frame #20: <unknown function> + 0x1628b (0x7f848099428b in /home/junho/.local/lib/python3.8/site-packages/dgl/_ffi/_cy3/core.cpython-38-x86_64-linux-gnu.so)
<omitting python frames>
frame #23: python3() [0x50a23e]
frame #30: python3() [0x67d5a1]
frame #31: python3() [0x67d61f]
frame #36: __libc_start_main + 0xf3 (0x7f84fff290b3 in /lib/x86_64-linux-gnu/libc.so.6)

Aborted
========================================================================
Using backend: pytorch
Number of node : 200000, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.61201s | 100.0%
- Pytorch Geometric              |      1 |     2.77655s | 100.0%
- Random data processing         |      1 |     5.41993s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 200000, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.49400s | 100.0%
- Pytorch Geometric              |      1 |     1.34995s | 100.0%
- Random data processing         |      1 |     2.72973s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 200000, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.22845s | 100.0%
- Pytorch Geometric              |      1 |     0.22833s | 100.0%
- Random data processing         |      1 |     0.81296s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 200000, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.19833s | 100.0%
- Pytorch Geometric              |      1 |     0.09163s | 100.0%
- Random data processing         |      1 |     0.38195s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 200000, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 158, in <module>
    data_dgl = from_scipy(sparse.coo_matrix((data, (col, row))), eweight_name='w').to('cuda')
  File "/home/junho/.local/lib/python3.8/site-packages/dgl/convert.py", line 1080, in from_scipy
    raise DGLError('Expect the number of rows to be the same as the number of columns for '
dgl._ffi.base.DGLError: Expect the number of rows to be the same as the number of columns for sp_mat, got 199999 and 200000.
========================================================================
Using backend: pytorch
Number of node : 300000, Number of node features : 128, Number of classes : 10
Density : 0.1, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 112, in <module>
    adj = sparse.random(MAT_SIZE, MAT_SIZE, density=DENSITY, dtype=np.float32, random_state=np.random.default_rng())
  File "/home/junho/.local/lib/python3.8/site-packages/scipy/sparse/construct.py", line 806, in random
    ind = random_state.choice(mn, size=k, replace=False)
  File "_generator.pyx", line 788, in numpy.random._generator.Generator.choice
numpy.core._exceptions.MemoryError: Unable to allocate 671. GiB for an array with shape (90000000000,) and data type int64
========================================================================
Using backend: pytorch
Number of node : 300000, Number of node features : 128, Number of classes : 10
Density : 0.05, Random seed : 34, Epoch : 0
Traceback (most recent call last):
  File "crosskernel/benchmark2.py", line 112, in <module>
    adj = sparse.random(MAT_SIZE, MAT_SIZE, density=DENSITY, dtype=np.float32, random_state=np.random.default_rng())
  File "/home/junho/.local/lib/python3.8/site-packages/scipy/sparse/construct.py", line 806, in random
    ind = random_state.choice(mn, size=k, replace=False)
  File "_generator.pyx", line 788, in numpy.random._generator.Generator.choice
numpy.core._exceptions.MemoryError: Unable to allocate 671. GiB for an array with shape (90000000000,) and data type int64
========================================================================
Killed
========================================================================
Killed
========================================================================
Using backend: pytorch
Number of node : 300000, Number of node features : 128, Number of classes : 10
Density : 0.001, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     1.45841s | 100.0%
- Pytorch Geometric              |      1 |     6.89974s | 100.0%
- Random data processing         |      1 |    14.80696s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 300000, Number of node features : 128, Number of classes : 10
Density : 0.0005, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.77157s | 100.0%
- Pytorch Geometric              |      1 |     3.36495s | 100.0%
- Random data processing         |      1 |     7.04737s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 300000, Number of node features : 128, Number of classes : 10
Density : 0.0001, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.31504s | 100.0%
- Pytorch Geometric              |      1 |     0.54420s | 100.0%
- Random data processing         |      1 |     1.49470s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 300000, Number of node features : 128, Number of classes : 10
Density : 5e-05, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.24088s | 100.0%
- Pytorch Geometric              |      1 |     0.23567s | 100.0%
- Random data processing         |      1 |     0.95167s | 100.0%
-----------------------------------------------------------------

========================================================================
Using backend: pytorch
Number of node : 300000, Number of node features : 128, Number of classes : 10
Density : 1e-05, Random seed : 34, Epoch : 0
--- Timer summary -----------------------------------------------
  Event                          |  Count | Average time |  Frac.
- Deep Graph Library             |      1 |     0.20382s | 100.0%
- Pytorch Geometric              |      1 |     0.04506s | 100.0%
- Random data processing         |      1 |     0.40294s | 100.0%
-----------------------------------------------------------------

